{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "leap year\n"
     ]
    }
   ],
   "source": [
    "import winsound\n",
    "a=int(input())\n",
    "if a%4==0 or a%400==0:\n",
    "    print(\"leap year\")\n",
    "    winsound.PlaySound('alert.wav', winsound.SND_ASYNC)\n",
    "else:\n",
    "    print(\"no leap year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outside 395.20000000000005\n",
      "outside 49.60000000000002\n",
      "outside 3.1999999999999886\n",
      "outside 19.19999999999999\n",
      "outside 16.0\n",
      "outside 88.0\n",
      "outside 86.40000000000003\n",
      "outside 57.599999999999966\n",
      "outside 44.80000000000001\n",
      "outside 57.60000000000002\n",
      "outside 84.80000000000001\n",
      "outside 86.39999999999998\n",
      "outside 124.80000000000001\n",
      "outside 115.19999999999999\n",
      "outside 56.0\n",
      "outside 134.40000000000003\n",
      "outside 84.79999999999998\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import pyautogui\n",
    "cap = cv2.VideoCapture(0)\n",
    "hand_detector = mp.solutions.hands.Hands()\n",
    "drawing_utils = mp.solutions.drawing_utils\n",
    "screen_width, screen_height = pyautogui.size()\n",
    "index_y = 0\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    output = hand_detector.process(rgb_frame)\n",
    "    hands = output.multi_hand_landmarks\n",
    "    if hands:\n",
    "        for hand in hands:\n",
    "            drawing_utils.draw_landmarks(frame, hand)\n",
    "            landmarks = hand.landmark\n",
    "            for id, landmark in enumerate(landmarks):\n",
    "                x = int(landmark.x*frame_width)\n",
    "                y = int(landmark.y*frame_height)\n",
    "                if id == 8:\n",
    "                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255))\n",
    "                    index_x = screen_width/frame_width*x\n",
    "                    index_y = screen_height/frame_height*y\n",
    "\n",
    "                if id == 4:\n",
    "                    cv2.circle(img=frame, center=(x,y), radius=10, color=(0, 255, 255))\n",
    "                    thumb_x = screen_width/frame_width*x\n",
    "                    thumb_y = screen_height/frame_height*y\n",
    "                    print('outside', abs(index_y - thumb_y))\n",
    "                    if abs(index_y - thumb_y) < 20:\n",
    "                        pyautogui.click()\n",
    "                        pyautogui.sleep(1)\n",
    "                    elif abs(index_y - thumb_y) < 100:\n",
    "                        pyautogui.moveTo(index_x, index_y)\n",
    "cv2.imshow('Virtual Mouse', frame)\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "webbrowser.open_new_tab(\"http://localhost:8888/notebooks/coder%20for%20me.ipynb\")\n",
    "#webbrowser.get('google-chrome')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "from pynput.keyboard import Controller\n",
    "from time import sleep\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "camIndex=0\n",
    "cap=cv2.VideoCapture(camIndex)\n",
    "mpHands=mp.solutions.hands\n",
    "Hands=mpHands.Hands()\n",
    "mpDraw=mp.solutions.drawing_utils\n",
    "\n",
    "keys = [[\"Q\", \"W\", \"E\", \"R\", \"T\", \"Y\", \"U\", \"I\", \"O\", \"P\"],\n",
    "        [\"A\", \"S\", \"D\", \"F\", \"G\", \"H\", \"J\", \"K\", \"L\", \";\"],\n",
    "        [\"Z\", \"X\", \"C\", \"V\", \"B\", \"N\", \"M\", \",\", \".\", \"/\"]]\n",
    "keyboard = Controller()\n",
    "\n",
    "class Store():\n",
    "    def __init__(self,pos,size,text):\n",
    "        self.pos=pos\n",
    "        self.size=size\n",
    "        self.text=text\n",
    "    \n",
    "def draw(img,storedVar):\n",
    "    for button in storedVar:\n",
    "        x, y = button.pos\n",
    "        w, h = button.size\n",
    "        cv2.rectangle(img, button.pos, (x + w, y + h), (64, 64, 64), cv2.FILLED)\n",
    "        cv2.putText(img, button.text, (x+10, y+43),cv2.FONT_HERSHEY_PLAIN, 3, (255, 255, 255), 2)\n",
    "    return img\n",
    "\n",
    "StoredVar = []\n",
    "for i in range(len(keys)):\n",
    "    for j, key in enumerate(keys[i]):\n",
    "        StoredVar.append(Store([60 * j + 10, 60 * i + 10], [50,50],key))\n",
    "\n",
    "\n",
    "\n",
    "while (cap.isOpened()):\n",
    "    success_,img=cap.read()\n",
    "    cvtImg=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results=Hands.process(cvtImg)\n",
    "    lmList=[]\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for img_in_frame in results.multi_hand_landmarks:\n",
    "            mpDraw.draw_landmarks(img, img_in_frame, mpHands.HAND_CONNECTIONS)\n",
    "        for id,lm in enumerate(results.multi_hand_landmarks[0].landmark):\n",
    "            h,w,c=img.shape\n",
    "            cx,cy=int(lm.x*w),int(lm.y*h)\n",
    "            lmList.append([cx,cy])\n",
    "\n",
    "    if lmList:\n",
    "        for button in StoredVar:\n",
    "            x, y = button.pos\n",
    "            w, h = button.size\n",
    " \n",
    "            if x < lmList[8][0] < x + w and y < lmList[8][1] < y + h:\n",
    "                cv2.rectangle(img, (x - 5, y - 5), (x + w + 5, y + h + 5), (0, 0, 255), cv2.FILLED)\n",
    "                x1,y1=lmList[8][0],lmList[8][1]\n",
    "                x2,y2=lmList[12][0],lmList[12][1]\n",
    "                l=math.hypot(x2-x1-30,y2-y1-30)\n",
    "                print(l)\n",
    "                ## when clicked\n",
    "                if not l > 63:\n",
    "                    keyboard.press(button.text)\n",
    "                    cv2.rectangle(img, (x - 5, y - 5), (x + w + 5, y + h + 5), (0, 255, 0), cv2.FILLED)\n",
    "                    sleep(0.15)\n",
    "\n",
    "\n",
    "    img = draw(img, StoredVar)\n",
    "\n",
    "    cv2.imshow(\"Hand Tracking\",img)\n",
    "\n",
    "    if cv2.waitKey(1)==113: #Q=113\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b560f714d99e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'‪E:\\Sifat\\pic\\forhad vai.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'gray img'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "img = cv2.imread('‪E:\\Sifat\\pic\\forhad vai.jpg')\n",
    "imgray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('gray img',img)\n",
    "cv2.waitkey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
